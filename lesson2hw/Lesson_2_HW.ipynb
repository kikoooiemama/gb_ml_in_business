{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf2ac2b",
   "metadata": {},
   "source": [
    "# Практическое задание №2 по теме \"Профилирование пользователей. Сегментация аудитории: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f90bc5",
   "metadata": {},
   "source": [
    "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "3. Повторить п.2, но используя уже не медиану, а max\n",
    "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c6e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pymorphy2\n",
    "import itertools\n",
    "import nltk\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e563a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'Mean':[], 'Median':[], 'Max':[]} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3fb3d1",
   "metadata": {},
   "source": [
    "## Задание №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771c1d7",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html <br>\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57283de2",
   "metadata": {},
   "source": [
    "С информацией по ссылкам ознакомился."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc55f28",
   "metadata": {},
   "source": [
    "## Задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f25377",
   "metadata": {},
   "source": [
    "#### Формирование векторного представления новостей и инициализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449a99",
   "metadata": {},
   "source": [
    "1. Загрузка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383a8986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"materials.csv\")\n",
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "target = pd.read_csv(\"users_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc370d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "stopword_ru = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0149e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21ff2a",
   "metadata": {},
   "source": [
    "2. Предобработка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab045d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация (морфоанализатор)\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова \n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754ecea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_2020\\974220112.py:15: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Очистка текста\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2458c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Лемматизация очищенного текста\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0dc79",
   "metadata": {},
   "source": [
    "3. Словарь слов из обработанных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5226bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [t for t in news['title'].values]\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e894a",
   "metadata": {},
   "source": [
    "4. LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a9ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_topics = 25 # 25\n",
    "N_words = 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95aad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26.2 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda = LdaModel(common_corpus, num_topics=N_topics, id2word=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56df93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение LDA модели.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98e04ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: человек это который год ребёнок обнаружить тело\n",
      "topic_1: статья nn год писать москва исследование который\n",
      "topic_2: год млрд исследование рост млн рынок китай\n",
      "topic_3: квартира температура выяснить журнал градус отдых констатировать\n",
      "topic_4: сон лесной сергеев норматив калининградский браун азербайджан\n",
      "topic_5: газ турция турецкий офицер фильм превысить высота\n",
      "topic_6: год который nn смерть время стать это\n",
      "topic_7: год компания экономика журнал млн который цена\n",
      "topic_8: продукция энергия сотрудничать сближение пищевой хабаровский индустрия\n",
      "topic_9: это который мочь свой всё говорить год\n",
      "topic_10: медведев определение музыка лодка эксперимент студия орден\n",
      "topic_11: мозг исследование поверхность пациент день врач лечение\n",
      "topic_12: который операция nn это научный космос человек\n",
      "topic_13: который год это страна россия nn новый\n",
      "topic_14: рубль банк год который дело суд это\n",
      "topic_15: год россия украина это сша гражданин который\n",
      "topic_16: египет ступень бензин билет фрагмент школьный пропасть\n",
      "topic_17: обращение планета теория умереть конструкция год зуб\n",
      "topic_18: достигать кремль величина грузия мотив арбитраж комплексный\n",
      "topic_19: фонд погибнуть год товар озеро город параметр\n",
      "topic_20: баланс собранный развивающийся актуальный си миля повторяться\n",
      "topic_21: год россия это который российский страна военный\n",
      "topic_22: проект первый это год станция весь который\n",
      "topic_23: вирус юг воздух пища необычный сигнал публикация\n",
      "topic_24: мышь выдать век ii дождь рим столетие\n"
     ]
    }
   ],
   "source": [
    "x = lda.show_topics(num_topics=N_topics, num_words=N_words, formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "for topic, words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdeded",
   "metadata": {},
   "source": [
    "5. Векторное представление новостей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d4a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(N_topics):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5e2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(N_topics)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(N_topics)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be650bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь новостей в векторном представлении\n",
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(N_topics)]].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2248aa",
   "metadata": {},
   "source": [
    "#### Обучение модели и вычисление метрик для get_user_embedding на основе среднего (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44e5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_mean(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afd5ca",
   "metadata": {},
   "source": [
    "Векторное представление пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bcb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_mean = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_mean(x), 1)])\n",
    "user_embeddings_mean.columns = ['topic_{}'.format(i) for i in range(N_topics)]\n",
    "user_embeddings_mean['uid'] = users['uid'].values\n",
    "user_embeddings_mean = user_embeddings_mean[['uid']+['topic_{}'.format(i) for i in range(N_topics)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91174ea7",
   "metadata": {},
   "source": [
    "Тренировочный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b1f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = pd.merge(user_embeddings_mean, target, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac7aa1",
   "metadata": {},
   "source": [
    "Обучение и предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcaa96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mean[['topic_{}'.format(i) for i in range(N_topics)]], \n",
    "                                                    X_mean['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "454f53c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbafb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a71b2",
   "metadata": {},
   "source": [
    "Вычисление метрик и оптимального порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34629c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = roc_auc_score(y_test, preds_mean)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_mean)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c8b50",
   "metadata": {},
   "source": [
    "Сохранение полученных результатов для \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8026015",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Mean'].append(thresholds[ix])\n",
    "result_dict['Mean'].append(fscore[ix])\n",
    "result_dict['Mean'].append(precision[ix])\n",
    "result_dict['Mean'].append(recall[ix])\n",
    "result_dict['Mean'].append(ras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad63ff",
   "metadata": {},
   "source": [
    "#### Обучение модели и вычисление метрик для get_user_embedding на основе медианы (median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ab5a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_median(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aae4a9",
   "metadata": {},
   "source": [
    "Векторное представление пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "128fb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_median = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_median(x), 1)])\n",
    "user_embeddings_median.columns = ['topic_{}'.format(i) for i in range(N_topics)]\n",
    "user_embeddings_median['uid'] = users['uid'].values\n",
    "user_embeddings_median = user_embeddings_median[['uid']+['topic_{}'.format(i) for i in range(N_topics)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a5d4f",
   "metadata": {},
   "source": [
    "Тренировочный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaa712d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_median = pd.merge(user_embeddings_median, target, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556891ad",
   "metadata": {},
   "source": [
    "Обучение и предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e604713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_median[['topic_{}'.format(i) for i in range(N_topics)]], \n",
    "                                                    X_median['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d11320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb5f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_median = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acda42",
   "metadata": {},
   "source": [
    "Вычисление метрик и оптимального порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac5f71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = roc_auc_score(y_test, preds_median)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_median)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fb8a7",
   "metadata": {},
   "source": [
    "Сохранение полученных результатов для \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7f00cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Median'].append(thresholds[ix])\n",
    "result_dict['Median'].append(fscore[ix])\n",
    "result_dict['Median'].append(precision[ix])\n",
    "result_dict['Median'].append(recall[ix])\n",
    "result_dict['Median'].append(ras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f064d94",
   "metadata": {},
   "source": [
    "## Задание №3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c16e02",
   "metadata": {},
   "source": [
    "#### Обучение модели и вычисление метрик для get_user_embedding на основе максимума (max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ab21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_max(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a38e28",
   "metadata": {},
   "source": [
    "Векторное представление пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b327e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_max = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_max(x), 1)])\n",
    "user_embeddings_max.columns = ['topic_{}'.format(i) for i in range(N_topics)]\n",
    "user_embeddings_max['uid'] = users['uid'].values\n",
    "user_embeddings_max = user_embeddings_max[['uid']+['topic_{}'.format(i) for i in range(N_topics)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d047373",
   "metadata": {},
   "source": [
    "Тренировочный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3208220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max = pd.merge(user_embeddings_max, target, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad6842",
   "metadata": {},
   "source": [
    "Обучение и предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86f840d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_max[['topic_{}'.format(i) for i in range(N_topics)]], \n",
    "                                                    X_max['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ae163ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "536d2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_max = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c1021",
   "metadata": {},
   "source": [
    "Вычисление метрик и оптимального порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f560d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = roc_auc_score(y_test, preds_max)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_max)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b9e6a",
   "metadata": {},
   "source": [
    "Сохранение полученных результатов для \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d7005e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Max'].append(thresholds[ix])\n",
    "result_dict['Max'].append(fscore[ix])\n",
    "result_dict['Max'].append(precision[ix])\n",
    "result_dict['Max'].append(recall[ix])\n",
    "result_dict['Max'].append(ras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123c927",
   "metadata": {},
   "source": [
    "## Задание №4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8013d",
   "metadata": {},
   "source": [
    "Дополнительное задание, решил его не выпонлять."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d3ff9",
   "metadata": {},
   "source": [
    "## Задание №5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f69f2b",
   "metadata": {},
   "source": [
    "N_topics = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "325be789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Best Threshold</th>\n",
       "      <td>0.257136</td>\n",
       "      <td>0.290724</td>\n",
       "      <td>0.323220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.754941</td>\n",
       "      <td>0.818004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.731801</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.779592</td>\n",
       "      <td>0.853061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_Auc_Score</th>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.967200</td>\n",
       "      <td>0.976959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean    Median       Max\n",
       "Best Threshold  0.257136  0.290724  0.323220\n",
       "F-Score         0.685185  0.754941  0.818004\n",
       "Precision       0.627119  0.731801  0.785714\n",
       "Recall          0.755102  0.779592  0.853061\n",
       "Roc_Auc_Score   0.952309  0.967200  0.976959"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_15 = pd.DataFrame(result_dict, index=['Best Threshold','F-Score','Precision','Recall','Roc_Auc_Score'])\n",
    "result_df_15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e08070",
   "metadata": {},
   "source": [
    "N_topics = 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f80f3aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Best Threshold</th>\n",
       "      <td>0.259007</td>\n",
       "      <td>0.284328</td>\n",
       "      <td>0.335070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.715356</td>\n",
       "      <td>0.765873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.745174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.779592</td>\n",
       "      <td>0.787755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_Auc_Score</th>\n",
       "      <td>0.946364</td>\n",
       "      <td>0.956688</td>\n",
       "      <td>0.968335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean    Median       Max\n",
       "Best Threshold  0.259007  0.284328  0.335070\n",
       "F-Score         0.666667  0.715356  0.765873\n",
       "Precision       0.586957  0.660900  0.745174\n",
       "Recall          0.771429  0.779592  0.787755\n",
       "Roc_Auc_Score   0.946364  0.956688  0.968335"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_25 = pd.DataFrame(result_dict, index=['Best Threshold','F-Score','Precision','Recall','Roc_Auc_Score'])\n",
    "result_df_25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc433228",
   "metadata": {},
   "source": [
    "## Задание №6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b64eb",
   "metadata": {},
   "source": [
    "Прогнал ноутбук для двух разных значений гиперпараметра \"количество тем\": 15 и 25. \n",
    "\n",
    "Получилось что по большинству показателей для обоих вариантов лидером оказался метод **Max**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e236e1",
   "metadata": {},
   "source": [
    "С чем это может быть связано? По сути по методу **Max** в каждом топике вероятность будет соответствовать максимальной вероятности, какая только может быть из статей, которые читал пользователь. Соответственно, разница в вероятностях между темами, которые были ярко выражены в прочитанной пользователем статье, и темами, которые в прочитанных статьях почти не фигурировали, будет довольно большой (серьезный разрыв в показателях вероятности между topics) по сравнению с разрывом в показателях вероятности между топиками расчитаным по методу **Mean**, **Median**. Из-за такого контраста, получается, что все прочитанные топики пользователем выражены ярче, отсюда скорее всего и более лучшие показатели метрик по методу **Max**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623faea",
   "metadata": {},
   "source": [
    "Что касается порога, то очевидно по методу **Max** он будет больше, так как полученные значения вероятности по каждому топику в среднем будут выше.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fa8c1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
